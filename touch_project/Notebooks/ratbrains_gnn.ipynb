{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-VuyDz9oQKt"
      },
      "outputs": [],
      "source": [
        "!pip install torch torch_geometric awkward gdown matplotlib numpy scipy networkx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Colab\\ Notebooks/A3D3_Workshop_2023_Dadarlatlab/A3D3_Hackathon_202307_Preprocessed"
      ],
      "metadata": {
        "id": "U5rOtnAYoSly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55d753b4-b393-4530-a6df-49dc11cc6e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1kFaLNqckbXtQ8RgJwPDjKW_PoX5e_Kyi/A3D3_Workshop_2023_Dadarlatlab/A3D3_Hackathon_202307_Preprocessed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --folder --id 1OUyLYTRGpM9KZWq6g1hFzcWu76EOldcz\n",
        "!gdown --folder --id 1mI0cTkS3BT2AlySiWaw51uUYlnMNwokd"
      ],
      "metadata": {
        "id": "J_LytptmoVpN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54239221-26f8-415d-9204-e0c2b145b875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Retrieving folder list\n",
            "Retrieving folder 1f7w_ZpYoj5kRMWD67X1GN_vxu-5M-_9e Behavior\n",
            "Processing file 15F5TY8QXaqB_zltGGpLlvchiOdHIQF90 limb1.avi\n",
            "Processing file 1bO1utwDxoyUoGHX2yjj385Uhz5bCR8Az limb2.avi\n",
            "Processing file 14gI2nNTv2_jG9kPgBce8a4vOnaWF6rpW touch_timestamps.csv\n",
            "Processing file 1vA1dljNg_AjUQkAPEyh2T-xCS6z86bP2 ffneu_final_neural_avg.png\n",
            "Processing file 1vA9XyGLnKMqx5s3ITk5_6kVijdU7ivX_ ffneu_final_neural.png\n",
            "Processing file 1ubHL4a_kuSTU2sMcz4FVg2iKXawSbmOz ffneu_final.npy\n",
            "Processing file 1ucpN2Rco5yqR40N2qVO1UbhHJH931p-I idx_coord_neural.npy\n",
            "Processing file 1uxDj9PG3kU5x8kA_AjpR6X31B14RpC-0 number_frames_hist.png\n",
            "Processing file 1umRjyumSvoFUIeXMxXdo0Cx0GN_awZB0 spks_final_neural_avg.png\n",
            "Processing file 1uwOyZ9WMXOZeJYZseCJ9Avi1jmFVDLCY spks_final_neural.png\n",
            "Processing file 1uhdTQb3OA_8aLWmt75tK6Csf6F1qxUBv spks_final.npy\n",
            "Processing file 1vEBUpF3SahWKGbb7RvEeFFqSRISsTpR7 stat.npy\n",
            "Processing file 1vCQ0tO5bDl8ctkuALdguwSWxvajuHrjw touch_behav.npy\n",
            "Processing file 1ub0RtzYIIWN7lRi9ebpysoExCHxcHcPB touch.png\n",
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15F5TY8QXaqB_zltGGpLlvchiOdHIQF90\n",
            "To: /content/Animal1_Touch/Behavior/limb1.avi\n",
            "100% 318M/318M [00:09<00:00, 34.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bO1utwDxoyUoGHX2yjj385Uhz5bCR8Az\n",
            "To: /content/Animal1_Touch/Behavior/limb2.avi\n",
            "100% 452M/452M [00:14<00:00, 31.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14gI2nNTv2_jG9kPgBce8a4vOnaWF6rpW\n",
            "To: /content/Animal1_Touch/Behavior/touch_timestamps.csv\n",
            "100% 866/866 [00:00<00:00, 5.01MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vA1dljNg_AjUQkAPEyh2T-xCS6z86bP2\n",
            "To: /content/Animal1_Touch/ffneu_final_neural_avg.png\n",
            "100% 99.7k/99.7k [00:00<00:00, 122MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vA9XyGLnKMqx5s3ITk5_6kVijdU7ivX_\n",
            "To: /content/Animal1_Touch/ffneu_final_neural.png\n",
            "100% 834k/834k [00:00<00:00, 178MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ubHL4a_kuSTU2sMcz4FVg2iKXawSbmOz\n",
            "To: /content/Animal1_Touch/ffneu_final.npy\n",
            "100% 168M/168M [00:02<00:00, 56.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ucpN2Rco5yqR40N2qVO1UbhHJH931p-I\n",
            "To: /content/Animal1_Touch/idx_coord_neural.npy\n",
            "100% 384k/384k [00:00<00:00, 163MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uxDj9PG3kU5x8kA_AjpR6X31B14RpC-0\n",
            "To: /content/Animal1_Touch/number_frames_hist.png\n",
            "100% 15.5k/15.5k [00:00<00:00, 59.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1umRjyumSvoFUIeXMxXdo0Cx0GN_awZB0\n",
            "To: /content/Animal1_Touch/spks_final_neural_avg.png\n",
            "100% 105k/105k [00:00<00:00, 138MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uwOyZ9WMXOZeJYZseCJ9Avi1jmFVDLCY\n",
            "To: /content/Animal1_Touch/spks_final_neural.png\n",
            "100% 544k/544k [00:00<00:00, 125MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uhdTQb3OA_8aLWmt75tK6Csf6F1qxUBv\n",
            "To: /content/Animal1_Touch/spks_final.npy\n",
            "100% 168M/168M [00:02<00:00, 73.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vEBUpF3SahWKGbb7RvEeFFqSRISsTpR7\n",
            "To: /content/Animal1_Touch/stat.npy\n",
            "100% 9.89M/9.89M [00:00<00:00, 30.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vCQ0tO5bDl8ctkuALdguwSWxvajuHrjw\n",
            "To: /content/Animal1_Touch/touch_behav.npy\n",
            "100% 1.50k/1.50k [00:00<00:00, 9.79MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ub0RtzYIIWN7lRi9ebpysoExCHxcHcPB\n",
            "To: /content/Animal1_Touch/touch.png\n",
            "100% 10.1k/10.1k [00:00<00:00, 24.6MB/s]\n",
            "Download completed\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Retrieving folder list\n",
            "Retrieving folder 1Tro1J8xHwQ0SkqID489ucOn2NfmD5iaS Behavior\n",
            "Processing file 1CRJM2vDeQ-XECpkJRorWxz-KCGY56Lvv limb1.avi\n",
            "Processing file 1kIPVNZq7d-nEHDLrkkSwi9WF-K-tdJg4 limb2.avi\n",
            "Processing file 1k2dTgIV40QUWRoyLmTuYmTD2AUb5DCwF touch_timestamps.csv\n",
            "Processing file 1vp6kvEoJ-I-NbbfdhbSHDBRVfBMKfxKK ffneu_final_neural_avg.png\n",
            "Processing file 1vrqxNZKNHSLb3O8JtafsFr6UbzIPSNT7 ffneu_final_neural.png\n",
            "Processing file 1vKNxPnQ3ZW58elIFZJ8S1CGPfO-RIQY_ ffneu_final.npy\n",
            "Processing file 1vaeUYc7xxP1Ohe_Vi44SuqcnY0OZSY25 idx_coord_neural.npy\n",
            "Processing file 1vjHBw38dD-gtQWTouMTnEQMXyJ6B1J7W number_frames_hist.png\n",
            "Processing file 1vfvEteY6nk4yRV_KYs-_0EuzQVUQN4Qq spks_final_neural_avg.png\n",
            "Processing file 1vhiqxX9lBbBZJfLxeTB1x7Z0Jkn4FtrI spks_final_neural.png\n",
            "Processing file 1va70bI7UyuEzWkM2vTMIiEbJJNHRqDc7 spks_final.npy\n",
            "Processing file 1vvns0jvEN1oJ9jjSlgPHExeCJr4_7jHO stat.npy\n",
            "Processing file 1vtU04mm1AqpaRRtsAjsW0dh_vpJivBaB touch_behav.npy\n",
            "Processing file 1vKA9TGeWyx2y6j7XmmmvdSbNSMa3k3w8 touch.png\n",
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CRJM2vDeQ-XECpkJRorWxz-KCGY56Lvv\n",
            "To: /content/Animal2_Touch/Behavior/limb1.avi\n",
            "100% 300M/300M [00:06<00:00, 45.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kIPVNZq7d-nEHDLrkkSwi9WF-K-tdJg4\n",
            "To: /content/Animal2_Touch/Behavior/limb2.avi\n",
            "100% 364M/364M [00:08<00:00, 41.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1k2dTgIV40QUWRoyLmTuYmTD2AUb5DCwF\n",
            "To: /content/Animal2_Touch/Behavior/touch_timestamps.csv\n",
            "100% 840/840 [00:00<00:00, 5.57MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vp6kvEoJ-I-NbbfdhbSHDBRVfBMKfxKK\n",
            "To: /content/Animal2_Touch/ffneu_final_neural_avg.png\n",
            "100% 104k/104k [00:00<00:00, 128MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vrqxNZKNHSLb3O8JtafsFr6UbzIPSNT7\n",
            "To: /content/Animal2_Touch/ffneu_final_neural.png\n",
            "100% 986k/986k [00:00<00:00, 119MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vKNxPnQ3ZW58elIFZJ8S1CGPfO-RIQY_\n",
            "To: /content/Animal2_Touch/ffneu_final.npy\n",
            "100% 83.5M/83.5M [00:01<00:00, 57.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vaeUYc7xxP1Ohe_Vi44SuqcnY0OZSY25\n",
            "To: /content/Animal2_Touch/idx_coord_neural.npy\n",
            "100% 363k/363k [00:00<00:00, 140MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vjHBw38dD-gtQWTouMTnEQMXyJ6B1J7W\n",
            "To: /content/Animal2_Touch/number_frames_hist.png\n",
            "100% 14.9k/14.9k [00:00<00:00, 72.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vfvEteY6nk4yRV_KYs-_0EuzQVUQN4Qq\n",
            "To: /content/Animal2_Touch/spks_final_neural_avg.png\n",
            "100% 99.8k/99.8k [00:00<00:00, 134MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vhiqxX9lBbBZJfLxeTB1x7Z0Jkn4FtrI\n",
            "To: /content/Animal2_Touch/spks_final_neural.png\n",
            "100% 625k/625k [00:00<00:00, 149MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1va70bI7UyuEzWkM2vTMIiEbJJNHRqDc7\n",
            "To: /content/Animal2_Touch/spks_final.npy\n",
            "100% 83.5M/83.5M [00:01<00:00, 81.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vvns0jvEN1oJ9jjSlgPHExeCJr4_7jHO\n",
            "To: /content/Animal2_Touch/stat.npy\n",
            "100% 5.36M/5.36M [00:00<00:00, 24.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vtU04mm1AqpaRRtsAjsW0dh_vpJivBaB\n",
            "To: /content/Animal2_Touch/touch_behav.npy\n",
            "100% 1.45k/1.45k [00:00<00:00, 10.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vKA9TGeWyx2y6j7XmmmvdSbNSMa3k3w8\n",
            "To: /content/Animal2_Touch/touch.png\n",
            "100% 10.0k/10.0k [00:00<00:00, 49.8MB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Dataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as colors\n",
        "import networkx as nx\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "import numpy as np\n",
        "import awkward as ak"
      ],
      "metadata": {
        "id": "0VdYUObkoff2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_npy_files(directory):\n",
        "    data_dict = {}  # Initialize an empty dictionary to store the data\n",
        "    for file_name in os.listdir(directory):  # Iterate over all files in the directory\n",
        "        if file_name.endswith('.npy'):  # Check if the file has a .npy extension\n",
        "            file_path = os.path.join(directory, file_name)  # Get the full path of the file\n",
        "            data = np.load(file_path, allow_pickle=True)  # Load the numpy array from the file\n",
        "            key = os.path.splitext(file_name)[0]  # Extract the file name without extension as the dictionary key\n",
        "            data_dict[key] = data  # Add the data to the dictionary with the corresponding key\n",
        "    return data_dict\n",
        "\n",
        "# Usage example\n",
        "directory_path = 'Animal1_Touch'  # Replace with the actual directory path\n",
        "train_set = load_npy_files(directory_path)  # Load .npy files from the specified directory\n",
        "train_set['stat'] = ak.from_iter(train_set['stat']) #convert from regular dictionary to awkward array\n",
        "\n",
        "\n",
        "directory_path = 'Animal2_Touch'  # Replace with the actual directory path\n",
        "test_set = load_npy_files(directory_path)  # Load .npy files from the specified directory\n",
        "test_set['stat'] = ak.from_iter(test_set['stat'])\n",
        "\n",
        "print(test_set.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9dE8Onvoghu",
        "outputId": "e7d738fd-db5d-4be9-dd67-fe37e60ba4d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['touch_behav', 'ffneu_final', 'idx_coord_neural', 'stat', 'spks_final'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data_set, time_threshold, distance_threshold, transform=None, pre_transform=None):\n",
        "        super(MyDataset, self).__init__(\".\", transform, pre_transform)\n",
        "        self.data_set = data_set\n",
        "        self.time_threshold = time_threshold\n",
        "        self.distance_threshold = distance_threshold\n",
        "\n",
        "        stat_med = torch.tensor(data_set['stat']['med'])\n",
        "        self.x_coord, self.y_coord = stat_med.T\n",
        "        self.prelabel = torch.tensor(data_set['touch_behav'][:, 2])\n",
        "\n",
        "\n",
        "    def create_edges_within_distance(self, points, distance_threshold):\n",
        "        x, y = points[0], points[1]\n",
        "        euclidean_distances = torch.sqrt(torch.pow(x[:, None] - x[None, :], 2) +\n",
        "                                         torch.pow(y[:, None] - y[None, :], 2)).to(torch.float32)\n",
        "\n",
        "        indices = torch.where(euclidean_distances <= distance_threshold)\n",
        "        edges = torch.stack(indices, dim=0)\n",
        "        edge_distances = euclidean_distances[indices]\n",
        "        return edges, edge_distances\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return []  # Not used in this example\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return []  # Not used in this example\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.data_set['idx_coord_neural'])\n",
        "\n",
        "    def get(self, i):\n",
        "        idx = self.data_set['idx_coord_neural'][i]\n",
        "\n",
        "        spks_final = self.data_set['spks_final'][:, idx]\n",
        "        mask = spks_final > self.time_threshold\n",
        "        x_coord = self.x_coord[mask].to(torch.float32)\n",
        "        y_coord = self.y_coord[mask].to(torch.float32)\n",
        "        t_spike = torch.tensor(spks_final[mask]).to(torch.float32)\n",
        "\n",
        "        x = torch.stack((x_coord, y_coord, t_spike), dim=1)  # Create the node features tensor\n",
        "\n",
        "        edge_index, edge_attr = self.create_edges_within_distance(x, self.distance_threshold)\n",
        "\n",
        "        label = self.prelabel[(self.data_set['touch_behav'][:, 0] <= i * 4) & (i * 4 <= self.data_set['touch_behav'][:, 1])].tolist()\n",
        "        label = label[0] if len(label) > 0 else 0\n",
        "\n",
        "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, graph_attr=i)\n",
        "        data.y = torch.tensor(label)\n",
        "\n",
        "        return data\n",
        "\n",
        "time_threshold = -1\n",
        "distance_threshold = 10000\n",
        "\n",
        "train_dataset = MyDataset(train_set, time_threshold, distance_threshold)\n",
        "test_dataset = MyDataset(test_set, time_threshold, distance_threshold)\n",
        "\n",
        "#to fully pregen dataset before training for speed up\n",
        "# Can skip this if dataset is ram intensive\n",
        "# train_dataset = [data for data in train_dataset]\n",
        "# test_dataset = [data for data in test_dataset]\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, num_workers=2)  # Adjust num_workers as needed\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, num_workers=2)  # Adjust num_workers as needed"
      ],
      "metadata": {
        "id": "mwvWGQO5ov20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = GCNConv(3, 16)\n",
        "        self.conv2 = GCNConv(16, 32)\n",
        "        self.conv3 = GCNConv(32, 64)\n",
        "        self.fc = torch.nn.Linear(64, 5)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x.double(), data.edge_index\n",
        "\n",
        "        # Node-level feature transformations\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "\n",
        "        # Global-level feature extraction via mean pooling\n",
        "        x = torch_geometric.nn.global_mean_pool(x, data.batch)\n",
        "\n",
        "        # Output layer\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "IEVscp2jqg2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "\n",
        "# We're using a GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize model and optimizer\n",
        "model = Net().double().to(device)\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Training function\n",
        "def train():\n",
        "    model.train()\n",
        "    loss_all = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output.to(device), torch.tensor(data.y).to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_all += data.num_graphs * loss.item()\n",
        "    return loss_all / len(train_dataset)\n",
        "\n",
        "# Testing function\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        pred = model(data).max(dim=1)[1]\n",
        "        correct += pred.eq(torch.tensor(data.y).to(device)).sum().item()\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, 101):\n",
        "    train_loss = train()\n",
        "    train_acc = test(train_loader)\n",
        "    test_acc = test(test_loader)\n",
        "    print(f'Epoch: {epoch}, Train Loss: {train_loss}, '\n",
        "          f'Train Acc: {train_acc}, Test Acc: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrIl4nU2qkUj",
        "outputId": "4e69fa37-90a3-414d-c65a-2f2f8c42e109"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-bcd8a8a4ab86>:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  loss = F.nll_loss(output.to(device), torch.tensor(data.y).to(device))\n",
            "<ipython-input-13-bcd8a8a4ab86>:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  correct += pred.eq(torch.tensor(data.y).to(device)).sum().item()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Train Loss: 0.16457785599956615, Train Acc: 0.9846804785526699, Test Acc: 0.9839499096080074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "9KzNK0mfU5JN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b10964ad-e315-4db1-a330-e1192d8babe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for data in train_dataset:\n",
        "    if data.y not in [0,1,2,3,4]:\n",
        "        print(data)"
      ],
      "metadata": {
        "id": "yJRFAcwbEO6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([data.y for data in train_dataset])"
      ],
      "metadata": {
        "id": "_9kBRigmQ4vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O5T-GGEFRshd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
